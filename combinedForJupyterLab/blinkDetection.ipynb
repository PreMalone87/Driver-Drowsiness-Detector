{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22204e9a-984e-4bd0-847a-637cf9d18a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18129523-c9c7-469b-8e4a-d364860bffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D = layers.Conv2D\n",
    "MaxPooling = layers.MaxPooling2D\n",
    "Dense = layers.Dense\n",
    "Flatten = layers.Flatten\n",
    "to_categorical =  tf.keras.utils.to_categorical\n",
    "img_width = 75\n",
    "img_height = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e08c8a19-bbb4-407a-8a7f-78f9cc4b6306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 86s 1us/step\n"
     ]
    }
   ],
   "source": [
    "inception = tf.keras.applications.InceptionV3(input_shape = (img_width, img_height, 3), include_top = False, weights = \"imagenet\")\n",
    "inception.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10330c6e-c776-4a02-9bd9-f215aaf2e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 75, 75, 3)]       0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 300)               614700    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                8080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 162       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,455,826\n",
      "Trainable params: 653,042\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model used in h5 file\n",
    "\n",
    "inputs = tf.keras.Input(shape=(75, 75, 3))\n",
    "#x = data_augmentation(inputs)\n",
    "#x = preprocess_input(x)\n",
    "x = inception(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(300,activation = 'relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(100,activation = 'relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(80,activation = 'relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(2,activation = 'softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True,shear_range=0.2, zoom_range=0.2)\n",
    "\n",
    "batch_size = 32\n",
    "#print(X_train.shape)\n",
    "#train_generator = data_generator.flow(X_train,y_train,batch_size)\n",
    "#steps_per_epoch = X_train.shape[0] // batch_size\n",
    "\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0)\n",
    "#model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics=['accuracy']) #tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.summary()\n",
    "#history = model.fit(train_generator,batch_size=batch_size, epochs=4 , validation_data= (X_test,y_test), steps_per_epoch = steps_per_epoch)#, callbacks = callbacks)\n",
    "\n",
    "#model.save(\"CEW.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af3baaa9-054a-4122-93c8-025134ae3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"D:\\\\DriverStateAnalysis\\\\DriverDrowsinessDetection\\\\blinkDetectionCode\\\\CEW.h5\")\n",
    "model  =  tf.keras.models.load_model(\"D:\\\\DriverStateAnalysis\\\\DriverDrowsinessDetection\\\\blinkDetectionCode\\\\CEW.h5\")\n",
    "image = cv2.imread(\"D:\\\\eyePics\\\\0.jpg\",0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0468e76-15ef-4c9a-8a52-e7e0246f8751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted :  0.998094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#plt.imshow(image,cmap=\"gray\")\n",
    "\n",
    "image = cv2.resize(image,(75,75))\n",
    "image = cv2.resize(image,(75,75))\n",
    "image = cv2.cvtColor(image,cv2.COLOR_GRAY2BGR)\n",
    "image = image/255.0\n",
    "image = [image]\n",
    "image = np.array(image)\n",
    "#print(image.shape)\n",
    "pred = model.predict(image)\n",
    "print(\"Predicted : \",pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e2acf-a032-41ba-ab7b-6208f86805f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
